{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo práctico 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tp-n2-aprendizaje-profundo-2021-by-datitos-v2.zip to /home/matias/curso-aprendizaje-profundo/tp2\n",
      "100%|██████████████████████████████████████| 1.63M/1.63M [00:00<00:00, 1.81MB/s]\n",
      "100%|██████████████████████████████████████| 1.63M/1.63M [00:00<00:00, 1.81MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c tp-n2-aprendizaje-profundo-2021-by-datitos-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  tp-n2-aprendizaje-profundo-2021-by-datitos-v2.zip\n",
      "  inflating: fifa2021_test.csv       \n",
      "  inflating: fifa2021_training.csv   \n"
     ]
    }
   ],
   "source": [
    "!unzip tp-n2-aprendizaje-profundo-2021-by-datitos-v2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('fifa2021_training.csv')\n",
    "df_infer = pd.read_csv('fifa2021_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breve análisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                            243620\n",
       "Name                   Adam Hellborg\n",
       "Natinality                    Sweden\n",
       "Overal                            64\n",
       "Potential                         73\n",
       "Height                           188\n",
       "Weight                            79\n",
       "PreferredFoot                      R\n",
       "BirthDate              July 30, 1998\n",
       "Age                               22\n",
       "PlayerWorkRate         Medium/Medium\n",
       "WeakFoot                           3\n",
       "SkillMoves                         2\n",
       "Value                        1.2e+06\n",
       "Wage                            1500\n",
       "Club                       IK Sirius\n",
       "Club_KitNumber                     2\n",
       "Club_JoinedClub         Jan. 8, 2020\n",
       "Club_ContractLength             2022\n",
       "BallControl                       62\n",
       "Dribbling                         55\n",
       "Marking                           60\n",
       "SlideTackle                       57\n",
       "StandTackle                       60\n",
       "Aggression                        71\n",
       "Reactions                         58\n",
       "Interceptions                     60\n",
       "Vision                            61\n",
       "Composure                         63\n",
       "Crossing                          44\n",
       "ShortPass                         67\n",
       "LongPass                          64\n",
       "Acceleration                      54\n",
       "Stamina                           66\n",
       "Strength                          70\n",
       "Balance                           54\n",
       "SprintSpeed                       46\n",
       "Agility                           58\n",
       "Jumping                           57\n",
       "Heading                           53\n",
       "ShotPower                         55\n",
       "Finishing                         39\n",
       "LongShots                         43\n",
       "Curve                             39\n",
       "FKAcc                             33\n",
       "Penalties                         43\n",
       "Volleys                           41\n",
       "GKDiving                          13\n",
       "GKHandling                        10\n",
       "GKKicking                         13\n",
       "GKReflexes                        12\n",
       "Sex                             Male\n",
       "Position                         MID\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionar datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_valid = train_test_split(df, stratify=df.Position, train_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "variables_descartar = [\n",
    "    'Position', # variable objetivo\n",
    "    'ID',\n",
    "    'Name',\n",
    "    'Natinality',\n",
    "    'BirthDate',\n",
    "    'Value',\n",
    "    'Wage',\n",
    "    'Club',\n",
    "    'Club_KitNumber',\n",
    "    'Club_JoinedClub',\n",
    "    'Club_ContractLength',\n",
    "]\n",
    "\n",
    "variables_categóricas = df.drop(columns=variables_descartar).select_dtypes(include=np.object).columns\n",
    "variables_numéricas   = df.drop(columns=variables_descartar).select_dtypes(include=np.number).columns\n",
    "\n",
    "transformador = make_column_transformer(\n",
    "    (OneHotEncoder(),  variables_categóricas), # PreferredFoot, PlayerWorkRate, Sex\n",
    "    (StandardScaler(), variables_numéricas),   # Overal, Potential, Height, etc.\n",
    "    remainder='drop' # descarta las columnas no mencionadas en las transformaciones\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar transformador\n",
    "\n",
    "Esencialmente, calculamos los **promedios** y las **desviaciones estándares** que usaremos para la estandarización.\n",
    "\n",
    "**ESTOS VALORES SOLO DEBEN SER OBTENIDOS DEL DATASET DE ENTRENAMIENTO**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('onehotencoder', OneHotEncoder(),\n",
       "                                 Index(['PreferredFoot', 'PlayerWorkRate', 'Sex'], dtype='object')),\n",
       "                                ('standardscaler', StandardScaler(),\n",
       "                                 Index(['Overal', 'Potential', 'Height', 'Weight', 'Age', 'WeakFoot',\n",
       "       'SkillMoves', 'BallControl', 'Dribbling', 'Marking', 'SlideTackle',\n",
       "       'StandTackle', 'Aggression', 'Reactions', 'Interceptions', 'Vision',\n",
       "       'Composure', 'Crossing', 'ShortPass', 'LongPass', 'Acceleration',\n",
       "       'Stamina', 'Strength', 'Balance', 'SprintSpeed', 'Agility', 'Jumping',\n",
       "       'Heading', 'ShotPower', 'Finishing', 'LongShots', 'Curve', 'FKAcc',\n",
       "       'Penalties', 'Volleys', 'GKDiving', 'GKHandling', 'GKKicking',\n",
       "       'GKReflexes'],\n",
       "      dtype='object'))])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformador.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformar datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el transformador se queja si falta alguna columna de df_train :/\n",
    "df_infer['Position'] = None\n",
    "\n",
    "\n",
    "X_train = transformador.transform(df_train)\n",
    "X_valid = transformador.transform(df_valid)\n",
    "X_infer = transformador.transform(df_infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformar variable objetivo\n",
    "\n",
    "Como la variable objetivo es del tipo string, hay que llevarla a un tipo numérico para que PyTorch pueda procesarla.\n",
    "\n",
    "Este transformador mapea posiciones DEF, FWD, GK, MID a enteros **y viceversa** — la transformación inversa será útil para convertir las predicciones (enteros) en posiciones otra vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "transformador_etiquetas = LabelEncoder()\n",
    "\n",
    "transformador_etiquetas.fit(df_train.Position)\n",
    "\n",
    "y_train = transformador_etiquetas.transform(df_train.Position)\n",
    "y_valid = transformador_etiquetas.transform(df_valid.Position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciar Datasets de PyTorch\n",
    "\n",
    "El aprendizaje profundo es especialmente efectivo para imágenes y texto; para datos tabulares (como un DataFrame) el aprendizaje de máquinas clásico suele funcionar bastante bien, de ahí que PyTorch no cuente con facilidades para tratar este tipo de problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Tabular(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = X.astype(np.float32) # soluciona \"Expected object of scalar type Float but got scalar type Double\"\n",
    "        self.y = y \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if self.y is None:\n",
    "            return self.X[item]\n",
    "        else:\n",
    "            return self.X[item], self.y[item]\n",
    "\n",
    "        \n",
    "ds_train = Tabular(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el dataset es liviano y entra en la memoria, para validación e inferencia en vez de hacer esto\n",
    "\n",
    "```python\n",
    "ds_valid = Tabular(X_valid, y_valid)\n",
    "ds_infer = Tabular(X_infer)\n",
    "```\n",
    "\n",
    "vamos a usar tensores simplemente para no complicarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  1.        ,  2.2005258 ,  1.7577571 ,\n",
       "         1.6827489 ,  0.69650096,  1.9552506 ,  2.9999895 , -0.49693993,\n",
       "         1.5163243 ,  1.0263261 ,  0.5255314 , -1.4219726 , -0.93868953,\n",
       "         0.10657337,  2.1206129 ,  0.13522774,  1.5071335 ,  2.1563685 ,\n",
       "         0.6801946 ,  1.1708272 ,  1.3763508 , -0.25280562,  0.7491539 ,\n",
       "         1.286718  , -2.0082333 , -0.4727765 , -0.531109  , -0.06149001,\n",
       "         1.7349557 ,  2.030825  ,  2.0725315 ,  1.5956575 ,  0.90770805,\n",
       "         0.6198386 ,  1.1499894 ,  1.857724  , -0.42461264, -0.31164196,\n",
       "        -0.19319764, -0.09562566], dtype=float32),\n",
       " 1)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciar DataLoaders de PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las cosas que `DataLoader` hace es convertir arreglos de NumPy en tensores de PyTorch.\n",
    "\n",
    "Como no vamos a hacer esto\n",
    "\n",
    "```python\n",
    "# sin shuffle porque validación e inferencia no requieren barajar sus elementos \n",
    "dl_valid = DataLoader(ds_valid, batch_size=32)\n",
    "dl_infer = DataLoader(ds_infer, batch_size=32)\n",
    "```\n",
    "\n",
    "vamos a definir tensores a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = torch.tensor(X_valid).float()\n",
    "X_infer = torch.tensor(X_infer).float()\n",
    "\n",
    "y_valid = torch.tensor(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN  = X_trans.shape[1]\n",
    "OUT = len(transformador_etiquetas.classes_)\n",
    "\n",
    "modelo = nn.Sequential(\n",
    "    nn.Linear(IN,  8),\n",
    "    nn.Linear( 8, 64), nn.ReLU(),\n",
    "    nn.Linear(64, 32), nn.ReLU(),\n",
    "    nn.Linear(32, OUT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterio = nn.CrossEntropyLoss()\n",
    "optimizador = torch.optim.Adam(modelo.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  |  Train loss: 1.171    Valid loss: 0.823    Valid accuracy: 0.67\n",
      "  1  |  Train loss: 0.616    Valid loss: 0.472    Valid accuracy: 0.82\n",
      "  2  |  Train loss: 0.396    Valid loss: 0.355    Valid accuracy: 0.87\n",
      "  3  |  Train loss: 0.325    Valid loss: 0.321    Valid accuracy: 0.88\n",
      "  4  |  Train loss: 0.300    Valid loss: 0.304    Valid accuracy: 0.88\n",
      "  5  |  Train loss: 0.288    Valid loss: 0.295    Valid accuracy: 0.88\n",
      "  6  |  Train loss: 0.279    Valid loss: 0.288    Valid accuracy: 0.88\n",
      "  7  |  Train loss: 0.274    Valid loss: 0.282    Valid accuracy: 0.88\n",
      "  8  |  Train loss: 0.269    Valid loss: 0.277    Valid accuracy: 0.89\n",
      "  9  |  Train loss: 0.265    Valid loss: 0.276    Valid accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "ÉPOCAS = 10\n",
    "\n",
    "for época in range(ÉPOCAS):\n",
    "    # activa capas Dropout, BatchNorm si las hubiese\n",
    "    modelo.train()\n",
    "\n",
    "    pérdidas_train = []\n",
    "    \n",
    "    for X_lote, y_lote in dl_train:\n",
    "        optimizador.zero_grad()\n",
    "\n",
    "        predicciones = modelo(X_lote)\n",
    "        pérdida = criterio(predicciones, y_lote)\n",
    "\n",
    "        pérdida.backward()\n",
    "        optimizador.step()\n",
    "        \n",
    "        pérdidas_train.append(pérdida.item())\n",
    "    \n",
    "    # desactiva capas Dropout, BatchNorm si las hubiese\n",
    "    modelo.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predicciones = modelo(X_valid)\n",
    "        pérdida = criterio(predicciones, y_valid)\n",
    "        \n",
    "        y_pred = predicciones.argmax(dim=1) # selecciona la clase con mayor probabilidad\n",
    "        \n",
    "        efectividad = balanced_accuracy_score(y_valid, y_pred)\n",
    "    \n",
    "    \n",
    "    print(f'{época:3d}  |  Train loss: {np.mean(pérdidas_train):.3f}    Valid loss: {pérdida:.3f}    Valid accuracy: {efectividad:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferir datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_infer = modelo(X_infer).argmax(dim=1)\n",
    "\n",
    "df_infer['Position'] = transformador_etiquetas.inverse_transform(y_infer)\n",
    "\n",
    "(\n",
    "    df_infer[['ID', 'Position']]\n",
    "    .rename(columns={'ID':'Id', 'Position':'Category'})\n",
    "    .to_csv('submit.csv', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subir predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 62.8k/62.8k [00:02<00:00, 26.4kB/s]\n",
      "Successfully submitted to T.P. N°2 - Aprendizaje Profundo 2021 by Datitos"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c tp-n2-aprendizaje-profundo-2021-by-datitos-v2 -f submit.csv -m \"Brasil, decime qué se siente\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
