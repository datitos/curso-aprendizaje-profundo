<!DOCTYPE html>
<html>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-V8X222K8YZ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-V8X222K8YZ');
  </script>

  <title>AP 2021</title>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <!--<link href="https://unpkg.com/tailwindcss@^2/dist/tailwind.min.css" rel="stylesheet">-->
  <link href="styles.css" rel="stylesheet">
</head>
<body class="bg-purple-100">
  <nav class="h-12 bg-white fixed top-0 inset-x-0 z-50">
    <div class="container mx-auto px-4 max-w-screen-xl w-full h-full flex justify-start items-center">
      <a href="#" class="flex items-center">
        <img height="20" src="img/nyan.png" class="h-10 mr-1">
        Datitos
      </a>
      <a href="#calendario" class="ml-32">
        Calendario
      </a>
      <a href="#formulario" class="ml-8">
        Inscripción
      </a>
    </div>
  </nav>

  <div class="container mx-auto px-4 max-w-screen-xl mt-20 mb-7">
    <div class="text-center mb-10">
      <h1>Aprendizaje profundo</h1>
      por Datitos / Otoño 2021
    </div>

    <p>Solo en los últimos cinco años, el aprendizaje profundo ha tomado al mundo por sorpresa, impulsando un rápido progreso en campos tan diversos como la visión por computadora, el procesamiento del lenguaje natural, el reconocimiento automático del habla, el aprendizaje por refuerzo y el modelado estadístico. </p>

    <p> Este curso representa nuestro intento de hacer que el aprendizaje profundo sea accesible, enseñandote los conceptos, el contexto y el código. Nos propusimos crear un recurso que simultáneamente pudiera: </p>
    <ol type="i">
      <li> estar disponible gratuitamente para todos; </li>
      <li> ofrecer suficiente profundidad técnica para proporcionar un punto de partida en el camino para convertirse realmente en un científico de aprendizaje automático aplicado; </li>
      <li> incluir código ejecutable, que muestre a los estudiantes cómo resolver problemas en la práctica. </li>
    </ol> 
    
    <section id="equipo">
      <h2>Instructores</h2>
      <div class="flex flex-wrap">
        <div class="p-4 text-center">
          <img src="img/luciano.jpg" class="h-32 mb-4 rounded-full">
          Luciano Robino
        </div>

        <div class="p-4 text-center">
          <img src="img/pablo.jpg" class="h-32 mb-4 rounded-full">
          <a href="http://dharma.frm.utn.edu.ar/perfil/pmarinozi">Pablo Marinozi</a>
        </div>

        <div class="p-4 text-center">
          <img src="img/matías.jpg" class="h-32 mb-4 rounded-full">
          Matías Battocchia<br>Coordinador
        </div>
      </div>
    </section>

    <section id="info">
      <h2>Organización y condiciones de cursado</h2>
      <p>Este curso implmentará la metodología llamada aula invertida.</p>
      <p>En un aula invertida: el materal de estudio está disponible todo el tiempo para los alumnos. Además se coordinan encuentros sincrónicos entre alumnos y docentes. Se espera que los alumnos estudien el material de manera asincrónica y que resuelvan los ejercicios propuestos. Es muy recomendable que los alumnos interactúen entre ellos fuera de los encuentros sincrónicos. En los encuentros sincrónicos, los docentes resolverán dudas tanto conceptuales como de aplicación. Además, los encuentros sincrónicos servirán para:</p>
      <ul>
      <li>Hacer puestas en común</li>
      <li>Resolver ejercicios</li>
      <li>Discutir otras alternativas de solución </li>
      <li>Presentar y resolver dudas</li>
      <li>Proponer sugerencias</li>
      <li>Promover la discusión de los temas del curso</li>
      </ul>
      <h3>Modalidades de cursado:</h3>
      <p>Este curso tiene dos modalidades de cursado</p>
      <ul>
      <li>Alumnos inscriptos:<ul>
      <li>Tendrán acceso al material.</li>
      <li>Tendrán seguimiento de avances.</li>
      <li>Serán evaluados en las tres instancian señaladas:<ul>
      <li>Ejercicios obligatorios</li>
      <li>Examen global</li>
      <li>Proyecto final</li></ul></li></ul></li>
      <li>Alumnos oyentes:<ul>
      <li>Solamente tendrán acceso al material.</li></ul></li>
      </ul>
      <h3>Prerequisistos:</h3>
      <ul>
      <li>Manejo básico de Python</li>
      <li>Cálculo de una variable y Cálculo vectorial</li>
      <li>Algebra lineal</li>
      <li>Conocimiento básico de probabilidad y estadística.</li>
      </ul>
      <h3>Condiciones del cursado</h3>
      <p>Dadas las características de un aula invertida, las clases sincrónicas no son de carácter obligatorio. Sin embargo, dado que son clases de consulta y de puesta en común, se recomienda la asistencia para un mejor desempeño durante el cursado.</p>
      <p>El material del curso consiste en:</p>
      <ul>
      <li>Clases grabadas disponibles desde los primeros días</li>
      <li>10 guías de trabajos prácticos. Estos en general tendrán dos partes<ul>
      <li>La primera consitirá en implementación y aplicación de los contenidos desarrollados hasta ese momento. Su entrega y resolución serán de caracter obligatorio.</li>
      <li>La segunda constará de preguntas que permiten apropiarse de los conceptos subyacentes en los contenidos. Es recomendable la resolución de estas preguntas, pues serán similares a las preguntas del examen global.</li></ul></li>
      <li>Se recomienda respetar las fechas de entrega acordadas durante el curso.</li>
      </ul>
      <h3>Examen global:</h3>
      <p>Una vez terminado el cronograma de las clases sincrónicas, se coordinará un examen global. Las preguntas de este examen serán similares a las preguntas conceptuales de los trabajos prácticos.</p>
      <h3>Proyecto final:</h3>
      <p>Para aprobar el curso se deberá presentar un proyecto final sobre alguno de los temas discutidos durante el cursado. Estos proyectos finales seran trabajos grupales que los alumnos propondrán. Ejemplos de posibles temas se encuentran en el apartado "Proyectos finales". Estos temas podran elegirse si alguno de los grupos no supiera que tema elegir para el trabajo final. Se espera que este trabajo final sea una producción propia del grupo, por lo que de haber plagio este sera fuertemente sancionado.</p>
      <h3>Programa:</h3>
      <h4>Unidad 1: Machine learning</h4>
      <ul>
      <li>Machine learning: Concepto</li>
      <li>Manipulación de data-sets</li>
      <li>Frameworks y entornos de ejecución</li>
      <li>Regresión lineal y redes de una capa</li>
      <li>Perceptrones multicapa y redes multicapa</li>
      <li>Overfitting y underfitting</li>
      <li>Backward propagation y Foward propagation</li>
      <li>Algoritmos de optimización:<ul>
      <li>Descenso de gradiente estocástico</li>
      <li>Momentum</li>
      <li>ADAGrad</li></ul></li>
      </ul>
      <h4>Unidad 2 Computer vision</h4>
      <ul>
      <li>Convolución: Concepto</li>
      <li>Redes neuronales convolucionales</li>
      <li>Pooling, padding y striding</li>
      <li>Batch normalization</li>
      <li>Arquitecturas de redes convolucionales</li>
      <li>Tranfer learning y Fine-tuning</li>
      <li>Deteccción de objetos</li>
      <li>Up-sampling y convolución transpuesta</li>
      <li>Segmentación semántica</li>
      <li>GANs</li>
      </ul>
      <h4>Unidad 3: Procesamiento de lenguaje natural</h4>
      <ul>
      <li>Modelos secuenciales y variables ocultas</li>
      <li>Perplejidad, verosimilitud y entropia</li>
      <li>Backpropagation dependiente del tiempo</li>
      <li>Recurrencias con compuertas y memoria: GRU y LSTM</li>
      <li>Recurrencia bidireccional</li>
      <li>Analisis de sentimiento</li>
      <li>Traducción automática y embeddings</li>
      <li>Atención:<ul>
      <li>Concepto</li>
      <li>Métricas</li>
      <li>Pooling</li>
      <li>Modelo de Bahdanau     </li>
      <li>Multiples cabezales     </li>
      <li>Autoatención</li></ul></li>
      <li>Transformers</li>
      <li>Transformers bidireccionales: BERT</li>
      <li>Aplicaciones de BERT</li>
      </ul>
      <h4>Unidad 4: Sistemas de recomendación</h4>
      <ul>
      <li>Sistemas de recomencación con datos explicitos<ul>
      <li>Factorización de matrices</li>
      <li>Sistemas de recomendación con ranking</li></ul></li>
      <li>Funciones de perdida para ranking<br /><ul>
      <li>Muestreo negativo     </li>
      <li>Sensibildiad a la secuencia: Caser</li>
      <li>Factorización de matrices: NeuMF    </li></ul></li>
      <li>Sistemas de recomencación con datos implicitos</li>
      <li>Máquinas de factorización     </li>
      <li>Máquinas de factorización profundas</li>
      </ul>    </section>

    <section id="tareas">
      <h2>Prácticos</h2>
      <h3>When to Hand in</h3>
      <p>The assignments are due at 11:59pm. The due dates for all assignments are on the syllabus page.</p>
      <h4>Late Policy:</h4>
      <ul>
      <li>All students have 4 free late days for the quarter.</li>
      <li>You may use up to 2 late days per assignment with no penalty.</li>
      <li>You may use late days for the assignments, project proposal, and project milestone.</li>
      <li>You may not use late days for the final project report.</li>
      <li>Once you have exhausted your free late days, we will deduct a late penalty of 25% per additional late day.</li>
      <li>Example: You submit A1 one day late, submit A2 three days late, and submit A3 two days late. You receive no penalty for A1, and exhaust one of your free late days. For A2 the first two late days exhaust two of your free late days; the third day late incurs a 25% penalty. For A2 the first late day exhausts your final free late day; the second late day incurs a 25% penalty.</li>
      <li>For the project proposal and milestone we will deduct late days from each group member independently.</li>
      </ul>
      <h3>Where to Hand in</h3>
      <p>You will hand in the assignments electronically through myth and GradeScope.</p>
      <p>For submission instructions follow the steps listed on the appropriate assignment page.
      Do not email us your assignments.</p>
      <h3>Collaboration Policy</h3>
      <ul>
      <li>Study groups are allowed and students may discuss in groups. However, we expect students to understand and complete their own assignments. Each student must write down the solutions independently (without referring to written notes from the joint session) and hand in one assignment per student.</li>
      <li>If you worked in a group, please put the names of your study group on your assignment on top.</li>
      <li>Honor Code: There are a number of solutions to assignments from past offerings of CS231n that have been posted online. We are aware of this, and expect that all work submitted by students will be their own. Like all other classes at Stanford, we take the student Honor Code seriously.</li>
      </ul>
      <h2>Proyecto</h2>
      <h3>Overview</h3>
      <p>The Course Project is an opportunity for you to apply what you have learned in class to a problem of your interest. Potential projects usually fall into these two tracks:</p>
      <ul>
      <li>Applications. If you're coming to the class with a specific background and interests (e.g. biology, engineering, physics), we'd love to see you apply ConvNets to problems related to your particular domain of interest. Pick a real-world problem and apply ConvNets to solve it.</li>
      <li>Models. You can build a new model (algorithm) with ConvNets, or a new variant of existing models, and apply it to tackle vision tasks. This track might be more challenging, and sometimes leads to a piece of publishable work.</li>
      </ul>
      <p>One restriction to note is that this is a Computer Vision class, so your project should involve pixels of visual data in some form somewhere. E.g. a pure NLP project is not a good choice, even if your approach involves ConvNets.</p>
      <p>To get a better feeling for what we expect from CS231n projects, we encourage you to take a look at the project reports from previous years:</p>
      <ul>
      <li>Spring 2017</li>
      <li>Winter 2016</li>
      <li>Winter 2015</li>
      </ul>
      <p>To inspire ideas, you might also look at recent deep learning publications from top-tier conferences, as well as other resources below.</p>
      <ul>
      <li>CVPR: IEEE Conference on Computer Vision and Pattern Recognition</li>
      <li>ICCV: International Conference on Computer Vision</li>
      <li>ECCV: European Conference on Computer Vision</li>
      <li>NIPS: Neural Information Processing Systems</li>
      <li>ICLR: International Conference on Learning Representations</li>
      <li>ICML: International Conference on Machine Learning</li>
      <li>Publications from the Stanford Vision Lab</li>
      <li>Awesome Deep Vision</li>
      <li>Past CS229 Projects: Example projects from Stanford's machine learning class</li>
      <li>Kaggle challenges: An online machine learning competition website. For example, a Yelp classification challenge.</li>
      </ul>
      <h3>Hay más</h3>
      <p>Sigue…</p>    </section>

    <section id="calendario">
      <h2 >Calendario</h2>

      <p>Updated lecture slides will be posted here shortly before each lecture. Other links contain last year's slides, which are mostly similar.</p>

      <p>Lecture notes will be uploaded a few days after most lectures. The notes (which cover approximately the first half of the course content) give supplementary detail beyond the lectures.</p>

      <table>
        <thead>
          <tr>
            <th>
              Clase
            </th>
            <th>
              Fecha
            </th>
            <th>
              Descripción
            </th>
            <th>
              Recursos
            </th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>
              1. Introducción, motivación y bienvenida
            </td>
            <td>
              15/02/2021
            </td>
            <td>
              <ul> <br><li> Definición de componentes claves  </li><br><li> Tipo de problemas de aprendizaje </li><br><li> Aprendizaje profundo en la vida cotidiana </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              2. Implementación de los modelos
            </td>
            <td>
              19/02/2021
            </td>
            <td>
              <ul><br><li> Frameworks de aprendizaje profundo </li><br><li> Entornos de ejecución </li><br><li> Manipulación y preprocesamiento de datos </li><br><li> Cálculo automático de gradientes </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              3. Redes neuronales de una capa
            </td>
            <td>
              22/02/2021
            </td>
            <td>
              <ul><br><li> Regresión lineal </li><br><li> Regresión SoftMax </li><br><li> Implementación desde cero </li><br><li> Implementación usando frameworks </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              4. Redes neuronales de multicapa
            </td>
            <td>
              26/02/2021
            </td>
            <td>
              <ul><br><li> Perceptrón Multicapa (MLP) </li><br><li> Foward Propagation </li><br><li> Backward Propagation </li><br><li> Implementación desde cero </li><br><li> Implementación usando frameworks </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              5. MLP a medida
            </td>
            <td>
              01/03/2021
            </td>
            <td>
              <ul><br><li> Capas y Bloques </li><br><li> Capas diseñadas a medida </li><br><li> Inicialización y manejo de parámetros </li><br><li> Operaciones de I/O </li><br><li> GPU </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              6. Algoritmos de Optimización
            </td>
            <td>
              05/03/2021
            </td>
            <td>
              <ul><br><li> Descenso de gradiente </li><br><li> Descenso estocástico de gradiente </li><br><li> Momentum </li><br><li> ADAGRAD </li><br><li> ADAM </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              7. Selección de modelos
            </td>
            <td>
              08/03/2021
            </td>
            <td>
              <ul><br><li> Underfittng </li><br><li> Overfitting </li><br><li> Regularización de los pesos </li><br><li> Dropout </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              8. Redes convolucionales (CNN)
            </td>
            <td>
              12/03/2021
            </td>
            <td>
              <ul><br><li> Convoluciones en imágenes </li><br><li> Pooling </li><br><li> Padding y striding </li><br><li> Arquitectura LeNet </li><br><li> Implementacion de LeNet </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              9. Arquitecturas CNN Modernas
            </td>
            <td>
              15/03/2021
            </td>
            <td>
              <ul><br><li> AlexNet e ImageNet </li><br><li> Bloques VGG </li><br><li> Bloques NiN </li><br><li> GoogLeNet y el bloque Inception </li><br><li> Batch Normalization </li><br><li> Conexiones residuales: ResNet </li><br><li> Bloques densos: DenseNet </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              10. Transfer Learning
            </td>
            <td>
              19/03/2021
            </td>
            <td>
              <ul><br><li> Redes preentrenadas </li><br><li> Fine-Tuning </li><br><li> Aplicación: Transferencia de estilos </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              11. Detección de Objetos
            </td>
            <td>
              22/03/2021
            </td>
            <td>
              <ul><br><li> Bounding Boxes </li><br><li> Detección multiescala: SSD </li><br><li> Detección basada en regiones: R-CNN </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              12. Upsampling
            </td>
            <td>
              26/03/2021
            </td>
            <td>
              <ul><br><li> Convolución traspuesta </li><br><li> Segmentación semática: FCN </li><br><li> Modelos generativos: GANs </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              13. Redes recurrentes: RNN
            </td>
            <td>
              29/03/2021
            </td>
            <td>
              <ul><br><li> Modelos secuenciales </li><br><li> Variables ocultas </li><br><li> Perplejidad, verosimilitud y entropia </li><br><li> Backpropagation con dependencia temporal </li><br><li> Implementación desde cero </li><br><li> Implementación usando frameworks </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              14. Arquitecturas RNN Modernas
            </td>
            <td>
              02/04/2021
            </td>
            <td>
              <ul><br><li> Recurrencias con compuertas: GRU </li><br><li> Recurrencia con memoria: LSTM </li><br><li> Recurrencia bidireccional </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              15. Analisis de sentimiento
            </td>
            <td>
              05/04/2021
            </td>
            <td>
              <ul><br><li> Implementación con RNN </li><br><li> Implementación con CNN </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              16. Traducción automática
            </td>
            <td>
              09/04/2021
            </td>
            <td>
              <ul><br><li> Problemas de secuencia a secuecia: Seq2Seq </li><br><li> Embeddings de palabras: Word2Vec </li><br><li> Embeddings de palabras: GloVe </li><br><li> Embeddings de morfemas: fastText </li><br><li> Implementación con RNN </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              17. Mecanismo de atencion
            </td>
            <td>
              12/04/2021
            </td>
            <td>
              <ul><br><li> Concepto de atención </li><br><li> Pooling de atención </li><br><li> Métricas de atención </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              18. Atención en RNN
            </td>
            <td>
              16/04/2021
            </td>
            <td>
              <ul><br><li> Modelo de Bahdanau </li><br><li> Multiples cabezales </li><br><li> Autoatención </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              19. Transformers
            </td>
            <td>
              19/04/2021
            </td>
            <td>
              <ul><br><li> MLP sensible a la posición </li><br><li> Normalización por capas </li><br><li> Atención con máscaras </li><br><li> Codificación posicional </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              20. Transformers bidireccionales: BERT
            </td>
            <td>
              23/04/2021
            </td>
            <td>
              <ul><br><li> Embeddings sensibles al contexto </li><br><li> Arquitectura independiete de la tarea </li><br><li> Modelado del lenguaje con máscaras </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              21. Aplicaciones de BERT
            </td>
            <td>
              26/04/2021
            </td>
            <td>
              <ul><br><li> Predicción de próxima oraciones </li><br><li> Etiquetado automático </li><br><li> Respuesta automatizada a preguntas </li><br><li> Inferencia del lenguaje </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              22. Sistemas de recomencación con datos explicitos
            </td>
            <td>
              30/04/2021
            </td>
            <td>
              <ul><br><li> Sistemas de recomencación: clasificación </li><br><li> Factorización de matrices </li><br><li> Predicción de calificación con autoencoder </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              23. Sistemas de recomendación con ranking
            </td>
            <td>
              03/05/2021
            </td>
            <td>
              <ul><br><li> Funciones de perdida para ranking </li><br><li> Muestreo negativo </li><br><li> Factorización de matrices con MLP: NeuMF </li><br><li> Sensibildiad a la secuencia:  Caser </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              24. Sistemas de recomencación con datos implicitos
            </td>
            <td>
              07/05/2021
            </td>
            <td>
              <ul><br><li> Máquinas de factorización </li><br><li> Máquinas de factorización Profundas </li><br></ul>
            </td>
            <td>
            </td>
          </tr>
          <tr>
            <td>
              Lecture 4
            </td>
            <td>
              Thursday April 16
            </td>
            <td>
              <b>Neural Networks and Backpropagation</b><br>Backpropagation<br>Multi-layer Perceptrons<br>The neural viewpoint
            </td>
            <td>
              <a href="#">slides</a><br>backprop notes<br>linear backprop example<br>derivatives notes (optional)<br>Efficient BackProp (optional)
            </td>
          </tr>
          <tr class="práctica">
            <td>
              Discussion Section
            </td>
            <td>
              Friday April 17
            </td>
            <td>
              Backprop tutorial
            </td>
            <td>
              slides<br>annotated slides
            </td>
          </tr>
          <tr class="entrega">
            <td>
              A1 Due
            </td>
            <td>
              Wednesday April 22
            </td>
            <td>
              Assignment 1 due<br>kNN, SVM, SoftMax, two-layer network
            </td>
            <td>
            </td>
          </tr>
        </tbody>
      </table>    </section>

    <section id="faq">
      <h2>FAQ</h2>
      <h4>What's the grading policy for Spring 2020?</h4>
      <p>According to the official faculty senate legislation, grading will be Satisfactory/No Credit (S/NC) for Spring 2020. We are still deciding on the grading details, and we will be updating them soon.</p>
      <h4>Academic accommodations:</h4>
      <p>If you need an academic accommodation based on a disability, you should initiate the request with the Office of Accessible Education (OAE). The OAE will evaluate the request, recommend accommodations, and prepare a letter for faculty. Students should contact the OAE as soon as possible and at any rate in advance of assignment deadlines, since timely notice is needed to coordinate accommodations. It is the student’s responsibility to reach out to the teaching staff regarding the OAE letter. Please send your letters to cs231n-spr1920-staff@lists.stanford.edu</p>
      <h4>Can I take this course on credit/no cred basis?</h4>
      <p>Yes. Credit will be given to those who would have otherwise earned a C- or above.</p>
      <h4>Can I audit or sit in?</h4>
      <p>In general we are very open to auditing if you are a member of the Stanford community (registered student, staff, and/or faculty). Out of courtesy, we would appreciate that you first email us or talk to the instructor after the first class you attend.</p>
      <h4>Can I work in groups for the Final Project?</h4>
      <p>Yes, in groups of up to three people.</p>
      <h4>I have a question about the class. What is the best way to reach the course staff?</h4>
      <p>Almost all questions should be asked on Piazza. If you have a sensitive issue you can email the instructors directly.</p>
      <h4>Can I combine the Final Project with another course?</h4>
      <p>Yes, you may; however before doing so you must receive permission from the instructors of both courses.</p>    </section>

    <section id="formulario">
      <h2>Inscripción</h2>

      <a href="https://docs.google.com/forms/d/e/1FAIpQLSe6UGJdHNcGhOL9Kcr1nVK2HNokTk6C39zb0XGKlQ7_mTROxw/viewform" class="md:hidden bg-white flow-root w-1/2 mx-auto p-4 text-center">Ir al formulario</a>

      <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSe6UGJdHNcGhOL9Kcr1nVK2HNokTk6C39zb0XGKlQ7_mTROxw/viewform?embedded=true" width="640" height="800" class="mx-auto hidden md:block">Cargando formulario de inscripción...</iframe>
    </section>
  </div>
</body>
</html>
