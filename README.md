# Curso Aprendizaje Profundo
## Cronograma

| |  |
|---|---|
|1. Introducción, motivación y bienvenida |15/02/2021|
| --> Definición de componentes claves| |
| --> Tipo de problemas de aprendizaje| |
| --> Aprendizaje profundo en la vida cotidiana| |
|||
|2. Implementación de los modelos |19/02/2021|
| --> Frameworks de aprendizaje profundo||
| --> Entornos de ejecución||
| --> Manipulación y preprocesamiento de datos||
| --> Cálculo automático de gradientes||
|||
|3. Redes neuronales de una capa|22/02/2021|
| --> Regresión lineal||
| --> Regresión SoftMax||
| --> Implementación desde cero||
| --> Implementación usando frameworks||
|||
|4. Redes neuronales de multicapa|26/02/2021|
| --> Perceptrón Multicapa (MLP)||
| --> Foward Propagation||
| --> Backward Propagation||
| --> Implementación desde cero||
| --> Implementación usando frameworks||
|||
|5. MLP a medida|01/03/2021|
| --> Capas y Bloques||
| --> Capas diseñadas a medida||
| --> Inicialización y manejo de parámetros||
| --> Operaciones de I/O||
| --> GPU||
|||
|6. Algoritmos de Optimización|05/03/2021|
| --> Descenso de gradiente||
| --> Descenso estocástico de gradiente||
| --> Momentum||
| --> ADAGRAD||
| --> Delta RMS||
| --> ADADelta||
| --> ADAM||
|||
|7. Selección de modelos|08/03/2021|
| --> Underfittng||
| --> Overfitting||
| --> Regularización de los pesos||
| --> Dropout||
|||
|8. Redes convolucionales (CNN)|12/03/2021|
| --> Convoluciones en imágenes||
| --> Pooling||
| --> Padding y striding||
| --> Arquitectura LeNet||
| --> Implementacion de LeNet||
|||
|9. Arquitecturas CNN Modernas|15/03/2021|
| --> AlexNet e ImageNet||
| --> Bloques VGG||
| --> Bloques NiN||
| --> GoogLeNet y el bloque Inception||
| --> Batch Normalization||
| --> Conexiones residuales: ResNet||
| --> Bloques densos: DenseNet||
|||
|10. Transfer Learning|19/03/2021|
| --> Redes preentrenadas||
| --> Fine-Tuning||
| --> Aplicación: Transferencia de estilos||
|||
|11. Detección de Objetos|22/03/2021|
| --> Bounding Boxes||
| --> Detección multiescala: SSD||
| --> Detección basada en regiones: R-CNN||
|||
|12. Convolución traspuesta|26/03/2021| <-- Revisar nombre!
| --> Convolución traspuesta||
| --> Segmentación semática: FCN||
| --> Modelos generativos: GANs||
|||
|13. Redes recurrentes: RNN|29/03/2021|
| --> Modelos secuenciales||
| --> Variables ocultas||
| --> Perplejidad, verosimilitud y entropia||
| --> Backpropagation con dependencia temporal||
| --> Implementación desde cero||
| --> Implementación usando frameworks||
|||
|14. Arquitecturas RNN Modernas|02/04/2021|
| --> Recurrencias con compuertas: GRU||
| --> Recurrencia con memoria: LSTM||
| --> Recurrencia bidireccional||
|||
|15. Analisis de sentimiento|05/04/2021|
| --> Implementación con RNN||
| --> Implementación con CNN||
|||
|16. Traducción automática|09/04/2021|
| --> Problemas de secuencia a secuecia: Seq2Seq||
| --> Embeddings de palabras: Word2Vec||
| --> Embeddings de palabras: GloVe||
| --> Embeddings de morfemas: fastText||
| --> Implementación con RNN||
|||
|17. Mecanismo de atencion|12/04/2021|
| --> Concepto de atención||
| --> Pooling de atención||
| --> Métricas de atención||
|||
|18. Atención en RNN|16/04/2021|
| --> Modelo de Bahdanau||
| --> Multiples cabezales||
| --> Autoatención|| <-- revisar nombre
|||
|19. Transformers|19/04/2021|
| --> MLP sensible a la posición||
| --> Normalización por capas||
| --> Atención con máscaras||
| --> Codificación posicional||
|||
|20. Transformers bidireccionales: BERT|23/04/2021|
| --> Embeddings sensibles al contexto||
| --> Arquitectura independiete de la tarea||
| --> Modelado del lenguaje con máscaras||
|||
|21. Aplicaciones de BERT|26/04/2021|
| --> Predicción de próxima oraciones||
| --> Etiquetado automático||
| --> Respuesta automatizada a preguntas||
| --> Inferencia del lenguaje||
|||
|22. Sistemas de recomencación con datos explicitos|30/04/2021|
| --> Sistemas de recomencación: clasificación ||
| --> Factorización de matrices||
| --> Predicción de calificación con autoencoder||
|||
|23. Sistemas de recomendación con ranking|03/05/2021|
| --> Funciones de perdida para ranking||
| --> Muestreo negativo||
| --> Factorización de matrices con MLP: NeuMF||
| --> Sensibildiad a la secuencia:  Caser||
|||
|24. Sistemas de recomencación con datos implicitos|07/05/2021|
| --> Máquinas de factorización||
| --> Máquinas de factorización Profundas||
